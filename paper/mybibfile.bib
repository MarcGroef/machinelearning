@inproceedings{van2007reinforcement,
  title="{Reinforcement Learning in Continuous Action Spaces}",
  author="H. Van Hasselt and M.A. Wiering",
  booktitle="Proceedings of the IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning, 2007",
  pages="272--279",
  year=2007,
  organization="IEEE"
}

@inproceedings{nichols2015continuous,
  title={{Continuous Action-Space Reinforcement Learning Methods Applied to the Minimum-Time Swing-up of the Acrobot}},
  author={Nichols, Barry D},
  booktitle={Systems, Man, and Cybernetics (SMC), 2015 IEEE International Conference on},
  pages={2084--2089},
  year={2015},
  organization={IEEE}
}

@inproceedings{cetina2008multilayer,
  title={{Multilayer Perceptrons with Radial Basis Functions as Value Functions in Reinforcement Learning}},
  author={Cetina, Victor Uc},
  booktitle={Proceedings of the 16th European Symposium on Artificial Neural Networks (ESANN)},
  pages={161--166},
  year={2008},
  organization={Citeseer}
}


@inproceedings{zimmer2016neural,
  title="{Neural Fitted Actor-Critic}",
  author="M. Zimmer and Y. Boniface and A. Dutech",
  booktitle="Proceedings of the European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2016)",
  year=2016,
  organization="ESANN"
}

@inproceedings{nichols2014application,
  title="{Application of Newton's Method to Action Selection in Continuous State- and Action-Space Reinforcement Learning}",
  author="B.D. Nichols and D.C. Dracopoulos",
  year=2014,
  booktitle="Proceedings of the European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)",
  organization="ESANN"
}

@inproceedings{kohl2004policy,
  title={{Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion}},
  author={N. Kohl and P. Stone},
  booktitle={Robotics and Automation, 2004. Proceedings. ICRA'04. 2004 IEEE International Conference on},
  volume={3},
  pages={2619--2624},
  year={2004},
  organization={IEEE}
}

@article{tesauro2002programming,
  title={Programming backgammon using self-teaching neural nets},
  author={G. Tesauro},
  journal={Artificial Intelligence},
  volume={134},
  number={1-2},
  pages={181--199},
  year={2002},
  publisher={Elsevier}
}

@article{baxter1999knightcap,
  title={{Knightcap: A chess program that learns by combining TD(lambda) with game-tree search}},
  author={J. Baxter and A. Tridgell and L. Weaver},
  journal={arXiv preprint cs/9901002},
  year={1999}
}
@article{ganeshdeep,
  title={{Deep Reinforcement Learning for Simulated Autonomous Driving}},
  author={A. Ganesh and J. Charalel and M. Das Sarma and N. Xu},
  year={2016}
}

@book{sutton1998reinforcement,
  title={{Reinforcement Learning: An Introduction}},
  author={R. Sutton and A.G. Barto},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@misc{openaigym,
  title = {{OpenAI Gym} {Main Webpage}},
  howpublished = {\url{https://gym.openai.com/}},
  note = {Accessed: 02-06-2017}
}

@misc{openaimountaincar,
  title = {{OpenAI Gym} {MountainCar} environment},
  howpublished = {\url{https://gym.openai.com/envs/MountainCarContinuous-v0}},
  note = {Accessed: 02-06-2017}
}

@misc{openailunarlander,
  title = {{OpenAI Gym} {LunarLander} environment},
  howpublished = {\url{https://gym.openai.com/envs/LunarLanderContinuous-v2}},
  note = {Accessed: 02-06-2017}
}
