%!TEX root = ../authorinstr.tex

\section{Background}

In Reinforcement Learning problems are modeled as Markov Decision Processes (MDP's). An MDP in the context of Reinfocement Learning
is a four-valued tuple $(S,A,R,T)$, where $S$ is a set of states that together make up the environment that a RL agent is in,
 $A$ is a set of actions the agent can take, $R: S \times A \times S \rightarrow \mathbb{R}$, is a reward function mapping a state the agent is in $s_t$,
 an action by the agent $a_t$ and the resulting new state of the agent $s_{t+1}$ to a reward $R(s_t,a_t,s_{t+1})$
 and $T: S \times A \times S \rightarrow [0,1]$ is a series of transition probabilites of $T()


 For Reinforcement Learning purposes the discount factor $\gamma$ is seen as part of the algorithm and not