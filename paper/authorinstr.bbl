\begin{thebibliography}{1}

\bibitem{tesauro2002programming}
G.~Tesauro.
\newblock Programming backgammon using self-teaching neural nets.
\newblock {\em Artificial Intelligence}, 134(1-2):181--199, 2002.

\bibitem{baxter1999knightcap}
J.~Baxter, A.~Tridgell, and L.~Weaver.
\newblock Knightcap: a chess program that learns by combining td (lambda) with
  game-tree search.
\newblock {\em arXiv preprint cs/9901002}, 1999.

\bibitem{kohl2004policy}
N.~Kohl and P.~Stone.
\newblock Policy gradient reinforcement learning for fast quadrupedal
  locomotion.
\newblock In {\em Robotics and Automation, 2004. Proceedings. ICRA'04. 2004
  IEEE International Conference on}, volume~3, pages 2619--2624. IEEE, 2004.

\bibitem{zimmer2016neural}
M.~Zimmer, Y.~Boniface, and A.~Dutech.
\newblock Neural fitted actor-critic.
\newblock In {\em Proceedings of the European Symposium on Artificial Neural
  Networks, Computational Intelligence and Machine Learning (ESANN 2016)}.
  ESANN, 2016.

\bibitem{van2007reinforcement}
H.~Van Hasselt and M.A. Wiering.
\newblock Reinforcement learning in continuous action spaces.
\newblock In {\em Proceedings of the IEEE International Symposium on
  Approximate Dynamic Programming and Reinforcement Learning, 2007}, pages
  272--279. IEEE, 2007.

\bibitem{sutton1998reinforcement}
R.~Sutton and A.G. Barto.
\newblock {\em Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem{openaimountaincar}
{OpenAI Gym} {MountainCar} environment.
\newblock \url{https://gym.openai.com/envs/MountainCarContinuous-v0}.
\newblock Accessed: 02-06-2017.

\bibitem{openailunarlander}
{OpenAI Gym} {LunarLander} environment.
\newblock \url{https://gym.openai.com/envs/LunarLanderContinuous-v2}.
\newblock Accessed: 02-06-2017.

\bibitem{openaigym}
{OpenAI Gym} {Main Webpage}.
\newblock \url{https://gym.openai.com/}.
\newblock Accessed: 02-06-2017.

\end{thebibliography}
